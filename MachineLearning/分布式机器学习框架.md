1.[链接](https://my.oschina.net/u/2306127/blog/634189)

分布式机器学习框架－TensorFlow on Spark(中) 转
 openthings   openthings 发布于 2016/03/10 09:22 字数 1931 阅读 820 收藏 4 点赞 2  评论 0
SparkPython机器学习
深度学习与 Spark 和 TensorFlow
在过去几年中，神经网络已经看到壮观进展，并且他们现在是图像识别和自动翻译领域中最强者。TensorFlow是数值计算和神经网络发布的谷歌的新框架。在这个博客中，我们将演示如何使用TensorFlow和Spark一起训练和应用深度学习模型。

你可能会困惑：在最高性能的深度学习实现是单节点的当下， Spark 的用处在哪里？为了回答这个问题，我们将会演示两个例子并解释如何使用 Spark 和机器集群搭配 TensorFlow 来提高深度学习的管道数。

超参数调整： 使用 Spark 来找到最好的神经网络训练参数集，减少十倍训练时间并减低34%的失误率。

部署模型规模： 使用 Spark 在大量数据上应用训练完毕的神经网络模型。

超参数调整
深度机器学习（ML）技术的一个例子是人工神经网络。它们采取一个复杂的输入，如图像或音频记录，然后应用复杂的数学变换这些信号。此变换的输出是更易于由其他ML算法操纵的数字向量。人工神经网络通过模仿人类大脑的视觉皮层的神经元（以相当简化的形式）执行该转换。

就像人类学会解读他们所看到的，人工神经网络需要通过训练来识别那些“有趣”的具体模式。例如，这些可以是简单的模式，例如边缘，圆形，但也可以是更复杂模式。在这里，我们将用NIST提供的经典数据集来训练神经网络识别这些数字：

image02.png

TensorFlow 库自动创建的各种形状和大小的神经网络训练算法。建立一个神经网络的实际过程，比在数据集上跑一些方法要复杂得多。通常有一些非常重要的超参数（通俗地 说，参数配置）来设置，这将影响该模型是如何训练的。选择正确的参数会导致性能优越，而坏的参数将会导致长时间的训练和糟糕的表现。在实践中，机器学习从 业者会多次使用不同的超参数运行相同的模型，以期找到最佳的集合。这是一个经典的技术，称为超参数调整。

建立一个神经网络时，有许多需要精心挑选的重要超参数。 例如：

在每个层的神经元数目：太少的神经元会降低网络的表达能力，但太多会大大增加运行时间，并返回噪音估计。

学习速度：如果过高，神经网络将只专注于看到过去的几样，并不顾一切之前积累的经验。如果太低，这将需要很长时间才能达到一个很好的状态。

这里有趣的是，即使 TensorFlow 本身不予分发，超参数调整过程是“embarrassingly parallel”，并且可以使用 Spark 分配。在这种情况下，我们可以使用 Spark 广播常见的元素，例如数据和模型描述，然后以容错方式安排跨越机器集群的个体进行重复计算。

image04.png

如何使用 Spark 提高精度？用默认的超参数设置精 度为99.2％。我们在测试集上的最好结果是99.47%的精确度，减少34％的测试误差。分布式计算时间与添加到集群节点的数量成线性关系：使用13个 节点的集群，我们能够同时培养13个模型，相比于在一台机器一个接着一个训练速度提升了7倍。这里是相对于该集群上机器的数量的计算时间（以秒计）的曲线 图：

image00-1024x436.png

最重要的是，我们分析了大量训练过程中的超参数的灵敏度。例如，我们相对于不同数目的神经元所得学习率绘制了最终测试性能图：

image03.png

这显示了一个典型的神经网络权衡曲线：

学习速度是非常关键的：如果它太低，神经网络没有学到任何东西（高测试误差）。如果它太高，训练过程可能发生随机振荡甚至在某些配置下出现发散。

神经元的数目对于获得良好的性能来说没有那么重要，并且有更多神经元的网络的学习率更加敏感。这是奥卡姆剃刀原则：对大多数目标来说，简单的模型 往往已经“足够好”。如果你有时间和资源来除去这缺少的1％测试误差，在训练中投入了大量的资源，并找到合适的超参数，这才会有所不同。

通过使用参数稀疏样本，我们可以在最优的参数集下取得零失误率。

我该如何使用它？
尽管 TensorFlow 可以使用每一个 worker 上的所有核心，我们只能在同一时间对每个工人运行一个任务，我们将它们打包以限制竞争。TensorFlow 库可以按照[instructions on the TensorFlow website]（https://www.tensorflow.org/get_started/os_setup.html）上的指示安装在 Spark 集群上作为一个普通的Python库。下面的笔记展示了如何安装TensorFlow并让用户重复该文章的实验：

Distributed processing of images using TensorFlow

Testing the distribution processing of images using TensorFlow

大规模部署
TensorFlow 模型可以直接在管道内嵌入对数据集执行复杂的识别任务。作为一个例子，我们将展示我们如何能够使用一个已经训练完成的股票神经网络模型标注一组图片

首先使用 Spark 内置的广播机制将该模型分发到集群中的worker上：

with gfile.FastGFile( 'classify_image_graph_def.pb', 'rb') as f:
model_data = f.read()
model_data_bc = sc.broadcast(model_data)
之后，这个模型被加载到每个节点上，并且应用于图片。这是每个节点运行的代码框架：

def apply_batch(image_url):
# Creates a new TensorFlow graph of computation and imports the model
with tf.Graph().as_default() as g:
graph_def = tf.GraphDef()
graph_def.ParseFromString(model_data_bc.value)
tf.import_graph_def(graph_def, name='')

# Loads the image data from the URL:
image_data = urllib.request.urlopen(img_url, timeout=1.0).read()

# Runs a tensor flow session that loads the 
with tf.Session() as sess:
  softmax_tensor = sess.graph.get_tensor_by_name('softmax:0')
  predictions = sess.run(softmax_tensor, {'DecodeJpeg/contents:0': image_data})
  return predictions
通过将图片打包在一起，这份代码可以运行地更快。 
下面是图片的一个样例:

image01.jpg

这是神经网络对于这张图片的解释，相当精确：

   ('coral reef', 0.88503921),
   ('scuba diver', 0.025853464),
   ('brain coral', 0.0090828091),
   ('snorkel', 0.0036010914),
   ('promontory, headland, head, foreland', 0.0022605944)])
期待
我们已经展示了如何将 Spark 和 TensorFlow结合起来训练和部署手写数字识别和图片分类的神经网络。尽管我们使用的神经网络框架自身只能在单节点运行，但我们可以用 Spark 分发超参数调节过程和模型部署。这不仅缩短了训练时间，而且还提高了精度，使我们更好地理解各种超参数的灵敏度。

尽管这支持是只适用于Python的，我们仍期待着可以提供 TensorFlow 和 Spark其它框架之间更深度的集成。

英文链接：http://my.oschina.net/u/2306127/blog/633605

英文原文：https://databricks.com/blog/2016/01/25/deep-learning-with-spark-and-tensorflow.html



本文转载自：https://databricks.com/blog/2016/01/25/deep-learning-with-spark-and-tensorflow.html

开源分布式机器学习工具

前面介绍了一下单机版的机器学习工具SPSS软件和RStudio，作为单机版的工具，不用关心集群配置和运维等操作，所以SPSS软件和RStudio都具有容易安装和上手的特点。

但是在实际的使用过程中，特别是数据量比较大的情况下，就会出现效率低下的问题。对大规模的机器学习计算，需要通过分布式架构进行处理，本节将重点介绍一下目前比较流行的两种支持分布式机器学习工具，分别是Spark MLib和Tensorflow。

1.2.1　Spark MLib

1．简介

MLib是Spark的机器学习算法库，是完全开源的。以Spark框架为基础构建的机器学习算法系统目前正在广泛地运用到各种领域当中。

既然要从处理实际的工业界场景的角度出发，Spark和Hadoop的MapReduce框架是目前业内最主流的两种开源分布式架构，难免要对它们进行一下对比，我们单从对机器学习算法的支持方面考虑如下。

（1）对多步迭代的支持。通过算法章节对算法的介绍，我们了解到大部分算法需要通过多步骤的迭代计算才可以实现，如梯度下降算法，需要通过多次迭代计算损失函数，然后才可以逐步逼近最优解。

传统的Hadoop的MapReduce计算框架，在每次迭代的过程中都需要对硬盘进行读写，这样就造成了很大的I/O消耗，降低了效率。

而Spark分布式计算框架是基于计算机内存来进行迭代计算的，通过将大量的计算工作在内存中处理的方式，可以大大减少对硬盘的数据读写，从而提高迭代类算法的计算效率。

（2）从集群通信的角度分析。Spark的Akka和Netty通信系统在信息传递和数据传递两方面，从效率上来讲都远远优于Hadoop的JobTracker间的通信机制。

以上两点是从分布式计算架构的角度分析得到的Spark相较于MapReduce的优势，下面介绍Spark MLib库的一些属性。

MLib 作为分布式机器学习算法库，设计的初衷是使机器学习算法更容易使用和扩展。

对数据集的支持方面，Spark MLib 支持本地的一些向量和矩阵数据，同时支持底层的弹性分布式数据集（RDD）。RDD是分布式内存的一个抽象概念，提供一种高度受限的内存模型，可以看作Spark MLib 的一个对象，运行在内存中。

以上是对Spark MLib的基础介绍，下面介绍如何构建Spark MLib机器学习系统。

2．安装配置环境

（1）首先下载Spark，实验环境为Mac OS，需要安装jdk。Spark下载地址为http://spark.apache.org/downloads.html，下载完成后解压，在命令行终端进入Spark目录，执行如下命令就可以启动Spark。

./sbin/start-master.sh

启动Spark之后，用户可以登录浏览器的localhost://8080 查看，如图1-14所示。

db739957c218c53bbf3c2d0b18828b7a

图1-14　登录Spark

（2）我们发现此时的Workers和Running Applications都是空的，因为Spark是基于分布式系统的计算框架，所以需要添加Worker才能让这个系统运行起来，否则是不能使用的。

为了方便讲解，这里把本机添加成Worker，添加其他集群机器的原理是相同的。添加Worker需要deploy worker的命令如下。

./bin/spark-class  org.apache.spark.deploy.worker.Worker spark://IP:PORT

如果添加的是本机，IP:Port可以通过图中的框线处得到，如图1-15所示。

9b8c4c0db1024f52186ece0f8e6c7350

 图1-15  IP图

将本机添加成Worker之后，再次刷新localhost:8080就可以看到Worker出现在列表中了，如图1-16所示。

92795f6578d3fc1bd61914174c5bd50c

图1-16　添加Worker

1.2.2　TensorFlow

1．简介

TensorFlow，是一个开源的机器学习框架，是基于著名的DistBelief开发的。最初的TensorFlow由“谷歌大脑”团队的研发人员开发，是用来研究深度神经网络的工具，但是随着架构的不断完善，整个系统已经被改造得可以适用于多种不同的场景。

Google在2015年将TensorFlow开源后，迅速得到来自IT行业各界的强烈反应。Android作为Google开源产品的标杆，已经占领了移动端市场，人们都在猜测，TensorFlow或许是Google进军人工智能市场的一把“尖刀”。

目前来看，TensorFlow具备着优良的特性，而且在新的版本中已经支持了分布式计算。在未来一段时间里，TensorFlow势必要引领机器学习的一段潮流。

先来简单介绍一下什么是TensorFlow，从字面意思来理解，Tensor 表示张量，是指任意维度的数据。在TensorFlow中，数据是通过数据流的形式在算法节点中流转的。我们通过深度学习的一张架构流程图（见图7-24）来解释。

f1f1dc99f4e7e698aa90ba8df16cc1f8

图1-17　深度学习

通过这张深度学习的架构图来分析，图1-17中竖形单元表示算法层，有输入层、隐藏层和输出层，每个圆形的单元是计算节点。

TensorFlow中的数据以数据流的形式在计算节点中流动。从前向后流，就是前向传播，从后向前流，就是后向传播，Flow表示的就是数据的这种流动。仅从字面意思来看，TensorFlow的具体计算形式已经表现得很清楚了。

下面简单介绍下TensorFlow的一些特性。

（1）灵活性。TensorFlow的灵活性不只表现在对算法的支持上，也表现在架构方面。TensorFlow支持单机计算和分布式计算，同时也可以将计算在CPU和GPU之间灵活切换。

在对算法的支持方面，TensorFlow不单单是一个神经网络库，它还可以看作机器学习的编程架构，开发者可以将自己的算法逻辑写成流图的形式，然后就可以把自己定义的算法运行在TensorFlow的架构中去。

（2）易用性。TensorFlow可以自动计算梯度，只需要手动设置好计算架构，设置好目标函数，然后向系统中灌入数据即可，中间的计算和参数权重变化都是自动完成的，同时系统也提供了办法帮助用户监督整个计算流程。

在具体使用方面，虽然TensorFlow的底层代码是通过C++来编写的，但是可以通过Python接口来创建计算流图。用户在逻辑代码的计算框架编写方面也比较容易上手。

（3）良好的资源调度能力。TensorFlow可以帮助开发者充分利用计算资源。对计算资源的调度可以高度自定义，可以自由调用CPU和GPU，同时也支持线程、队列和异步计算等。

TensorFlow让开发者可以充分利用自身的硬件资源，而且可以让数据流在不同的机器上自由流转。

2．实验环境搭建
前面介绍了TensorFlow的一些概要和基本性能，接下来介绍搭建TensorFlow的实验环境，并且跑通程序员们最熟悉的程序——Hello World。

（1）安装pip。pip是Mac系统中的一个Python的安装工具，TensorFlow可以通过pip自动安装，具体命令如下。

sudo easy_install pip 
sudo easy_install --upgrade six

如果已经安装了pip，可以忽略这一步.

（2）安装Virtualenv。Virtualenv是一个用于隔离本地Python环境的工具，因为TensorFlow在使用过程中需要对环境参数做一定的调整，所以推荐安装Virtualenv来进行隔离。

具体的操作步骤是首先安装Virtualenv，命令如下。

sudo pip install --upgrade virtualenv

然后在Virtualenv环境中创建一个tensorflow目录，命令如下。

virtualenv --system-site-packages ～/tensorflow

激活环境，可以通过activate和activate.csh两种方式，命令如下。

source ～/tensorflow/bin/activate# If using bash 
source ～/tensorflow/bin/activate.csh# If using csh

（3）安装TensorFlow。现在就可以通过pip在这个环境下安装TensorFlow了，根据Python的版本不同而选择不同的安装命令如下。

# Python 2
 (tensorflow)$ pip install --upgrade $TF_BINARY_URL 
# Python 3
(tensorflow)$ pip3 install --upgrade $TF_BINARY_URL

命令中的TF_BINARY_URL需要根据系统版本，Python版本是否支持GPU来进行选择。

# Mac OS X, CPU only, Python 2.7: 
(tensorflow)$export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.10.0-py2-none-any.whl

# Mac OS X, GPU enabled, Python 2.7: (tensorflow)$export 

TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/gpu/tensorflow-0.10.0-py2-none-any.whl

# Mac OS X, CPU only, Python 3.4 or 3.5:
(tensorflow)$export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.10.0-py3-none-any.whl 
 # Mac OS X, GPU enabled, Python 3.4 or 3.5: 
(tensorflow)$export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/gpu/tensorflow-0.10.0-py3-none-any.whl

（4）示例。前面已经把TensorFlow的计算环境安装完毕，我们激活Virtualenv下面的TensorFlow后，会进入到Python的隔离环境中，命令行终端的最前端会出现“tensorflow”的字样。下面介绍Hello world的执行代码。

#tf
import tensorflow as tf
hello = tf.constant('Hello world!') 
sess = tf.Session()
print(sess.run(hello))

constant是TensorFlow的一种数组，这里就不详细介绍了。下面主要来说一下Session的概念，Session表示会话的概念，在TensorFlow系统中，用户通过会话来与TensorFlow系统交互。一般的模式是先建立会话，然后在会话中添加节点和边，再通过Session来与TensorFlow交互。执行上面的这个代码文件，就会看到返回的结果，如图7-25所示。

d7ac09267f77ebaed57d1b550a0dc870

图1-18　结果

综上，一个单机版的TensorFlow就已经安装成功，并且跑通了Hello World实验。

企业级云机器学习工具

前面介绍的分别是单机版的机器学习工具和开源的分布式机器学习工具，虽然这些工具大多都具备友好的操作方式和丰富的算法，但是在企业级服务方面还是存在一些缺陷。接下来详细介绍亚马逊机器学习平台和阿里云机器学习平台PAI。

